{
  "name": "Athelas",
  "tagline": "",
  "body": "#A parallel random graph generation library.\r\n                                            By\r\n                            Karandeep Johar & Eshan Verma  \r\n                      kjohar@andrew.cmu.edu   everma@andrew.cmu.edu\r\n\r\n###SUMMARY:\r\nWe will implement a library to generate parallel large-scale graphs using OpenMP/pThreads exploiting CPU Architecture and using CUDA on GPUS. The aim is to compare implementation complexity, speed and resource efficiency.\r\n\r\n###BACKGROUND:\r\nProcessing Real World graphs is an active research problem. The real-world complex graphs are typically very large (with millions or more vertices) and their sizes grow over time. Some researchers predict that the size of these graphs will eventually reach 10^15 vertices. Unfortunately, we do not have publicly available real graphs that are large enough to test the functionality and true scalability of the graph applications. Hence, graph generation is an important field of research. There are many implementation and algorithms that exist but a serious drawback of these models is that they are all sequential models and thus, are inadequate in their usage to generate massive graphs with billions of vertices and edges.\r\n- Stochastic Kronecker Graph (A generalization of RMAT graph generation and ER)\r\n- Erdos-Renyi graph\r\n- Parallel Barabasi-Albert (PBA) method\r\n- CL method (Chung Lu)\r\n\r\nTo concentrate best on our aim of comparison of the implementation libraries, we implemented the SKG algorithm which is a generalization on the ER algorithm. The idea was to best optimize this algorithm over the various libraries to analyze the implementation and speedup.\r\n\r\nWe used SNAP and PaRMAT libraries for initial benchmarking and as code base. The evaluation of our algorithms and benchmarking was implemented by us. The checker functions to ensure that the properties for RMATs were ported from SNAP. Both these libraries provide different options for generations of graphs (directed vs. undirected, sorted vs. unsorted), we modeled our interface to support the same. To get optimal performance, we tuned our kernels/functions to take such parameters in to account.\r\n\r\n###THE CHALLENGE AND THE TACKLE\r\nOur project is different from most other tasks handled in this course. There is no reading of input data, rather a large amount of data is generated. Since each node is operated on independently, there is a large communication overhead to ensure connectivity amongst the nodes. Also, there is an inherent workload imbalance, the implementation had to be tuned to that particular use-cases. Along with that we ensured the following:\r\n\r\n1. Reducing communication between different parallel elements\r\n2. Distributing graph over the cores (load balancing)\r\n3. Writing efficiently to memory\r\n4. Compressed representation of the graph\r\n\r\n##APPROACH\r\nThere are three parts in the approach we adopted:\r\n(1) A Serial CPU Square Generation\r\nAll three implementations share a serial section in which the input matrix of edges to be generated is divided up in squares according to the probability distributions and these squares get a connection degree associated with them. The division can be seen in the figure.\r\n\r\n![SQ](https://github.com/AthelasCo/Athelas/blob/gh-pages/images/SQ.png?raw=true)\r\n\r\nNOTE: In our analysis, we have excluded timing of this section as a fixed overhead.\r\n\r\nThe next part was implemented differently according to the various optimizations available in the three libraries.\r\n\r\n(2.a) PTHREADs based Graph Generation\r\nWe followed a worker-queue based implementation for both scheduling the generation of the graph and writing it to file. The optimization over the baseline was better load balancing by scheduling squares better and determining size of squares better. The latency of writing to files was hidden by following a producer-consumer queue and the master thread handling all writes.\r\n\r\n(2.b) openMP Graph Generation\r\nThe openMP implementation was over all the squares in the list, and having a lock over over writing to file. The motivation behind this was to avoid having one thread idle during generation and have threads scheduled out while waiting over the lock so that generation time could be reduced.\r\n\r\n(2.c) CUDA Graph Generation\r\nThe kernel design for CUDA involved optimizing over sorted vs. non-sorted graph. At the block level we parallelized over all squares and within a block, the parallellization was over all source nodes. The graph was compressed by writing matrix offsets of edges generated to memory. Hence the compression of the graph helped in reducing the memory transfer overhead from the device. At the same time, the cost of expanding the graph is not much in the CPU. The serial algorithm for sorting was optimized to gain block locality and benefit from shared memory accesses as opposed to flushing to global memory. \r\n\r\n###RESULTS\r\n![Bug in code](https://github.com/AthelasCo/Athelas/blob/gh-pages/images/fused.png?raw=true)\r\nWe can see that the original implementation(in red) had a bug and did not actually get the in-degree  curve that we were looking for in a RMAT graph(our implementation in purple). This was an algorithmic change that was needed to ensure correctness as reported by SNAP. The same is ensured across implementations.\r\n\r\n###RESOURCES\r\n- We will be using the code present here as our starting point:\r\n[\"GitHub - snap-stanford/snap: Stanford Network Analysis ...\" 2012. 2 Apr. 2016](https://github.com/farkhor/PaRMAT)\r\n- The details of which are present in this paper:\r\n[Chakrabarti, Deepayan, Yiping Zhan, and Christos Faloutsos. \"R-MAT: A Recursive Model for Graph Mining.\" SDM. Vol. 4. 2004.](http://www.cs.ucr.edu/~gupta/research/Publications/Comp/wsvr.pdf)\r\nKhorasani, Farzad, Rajiv Gupta, and Laxmi N. Bhuyan. \"Scalable SIMD-Efficient Graph Processing on GPUs. \r\nand\r\n- SNAP, a library out of STANFORD which is based on OpenMPI and we will be referencing their solution as well:\r\n- [\"GitHub - snap-stanford/snap: Stanford Network Analysis ...\" 2012. 2 Apr. 2016](https://github.com/snap-stanford/snap/blob/master/examples/graphgen/graphgen.cpp)\r\n- [SNAP: Stanford Network Analysis Project.\" 2009. 2 Apr. 2016](http://snap.stanford.edu/class/cs224w-2012/projects/cs224w-035-final.v01.pdf)\r\n\r\n- Our initial understanding of RMATs was influenced by \r\n[Chakrabarti, Deepayan, Yiping Zhan, and Christos Faloutsos. \"R-MAT: A Recursive Model for Graph Mining.\" SDM. Vol. 4. 2004.](http://www.cs.cmu.edu/~christos/PUBLICATIONS/siam04.pdf)\r\n\r\n- And we will be referencing the following two papers for implementing a parallel Barabasi-Albert method and the Kronecker Graphs:\r\n-[ Yoo, Andy, and Keith Henderson. \"Parallel generation of massive scale-free graphs.\" arXiv preprint arXiv:1003.3684 (2010)] (http://arxiv.org/pdf/1003.3684v1.pdf%20Parallel%20Generation%20of%20Massive%20Scale-Free%20Graphs)\r\n- [Nobari, Sadegh, et al. \"Fast random graph generation.\" Proceedings of the 14th international conference on extending database technology. ACM, 2011] (http://karras.rutgers.edu/rg.pdf)\r\n\r\n- The CL Algorithm is from this paper:\r\n- [Alam, Maksudul, and Maleq Khan. \"Parallel Algorithms for Generating Random Networks with Given Degree Sequences.\" International Journal of Parallel Programming (2014): 1-19.](http://arxiv.org/pdf/1406.1215.pdf)\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}